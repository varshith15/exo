{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"METAL\"] = \"1\"\n",
    "# os.environ[\"CLANG\"] = \"1\"\n",
    "os.environ[\"METAL_XCODE\"] = \"1\"\n",
    "os.environ[\"DISABLE_COMPILER_CACHE\"] = \"1\"\n",
    "import numpy as np\n",
    "import mlx.core as mx\n",
    "from tinygrad import Tensor, dtypes, TinyJit\n",
    "from tinygrad.helpers import Timing\n",
    "import mlx.core as mx\n",
    "from mlx import nn as mlx_nn\n",
    "from tinygrad import nn\n",
    "# from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @TinyJit\n",
    "def kp(x:Tensor, y:Tensor):\n",
    "    return x.dot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = Tensor([[1, 2],[3, 4]])\n",
    "m = Tensor([[1, 2],[3, 4]])\n",
    "with Timing(\"Time: \"):\n",
    "    kp(l,m).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantized_matmul_tg(x, w_packed, scales, biases, width=4, groups=64):\n",
    "    M, K = x.shape\n",
    "    N, K_packed = w_packed.shape\n",
    "\n",
    "    num_values_per_uint32 = 32 // width  # E.g., for width=4, this is 8\n",
    "    K_unpacked = K_packed * num_values_per_uint32\n",
    "    num_groups = K // groups\n",
    "    packs_per_group = groups // num_values_per_uint32  # Number of uint32 packs per group\n",
    "\n",
    "    assert K == K_unpacked, f\"Mismatch in K dimensions: {K} vs {K_unpacked}\"\n",
    "    assert scales.shape == (N, num_groups), f\"Scales must have shape (N, {num_groups}), got {scales.shape}\"\n",
    "    assert biases.shape == (N, num_groups), f\"Biases must have shape (N, {num_groups}), got {biases.shape}\"\n",
    "    assert K % groups == 0, \"K must be divisible by the number of groups\"\n",
    "\n",
    "    # Prepare bitmask\n",
    "    bitmask = (1 << width) - 1  # E.g., for width=4, bitmask=15\n",
    "\n",
    "    # Reshape x for group-wise processing\n",
    "    x_grouped = x.reshape(M, num_groups, groups)  # Shape: (M, num_groups, groups)\n",
    "\n",
    "    # Initialize the output matrix\n",
    "    output = Tensor.zeros((M, N), dtype=dtypes.float16)\n",
    "\n",
    "    # Prepare shift amounts\n",
    "    shift_list = [i * width for i in range(num_values_per_uint32)]\n",
    "\n",
    "    # # Process each group\n",
    "    for g in range(num_groups):\n",
    "    #     # Extract scales and biases for the current group\n",
    "        scale_g = scales[:, g].reshape(N, 1)  # Shape: (N, 1)\n",
    "        bias_g = biases[:, g].reshape(N, 1)   # Shape: (N, 1)\n",
    "\n",
    "    #     # Extract the packed weights for the current group\n",
    "        pack_start = g * packs_per_group\n",
    "        pack_end = pack_start + packs_per_group\n",
    "        w_packed_group = w_packed[:, pack_start:pack_end]  # Shape: (N, packs_per_group)\n",
    "\n",
    "    #     # Initialize a list to collect unpacked values\n",
    "        unpacked_values = []\n",
    "\n",
    "    #     # Unpack the quantized weights\n",
    "        for shift_amount in shift_list:\n",
    "            # Perform the shift and mask operations\n",
    "            shifted = w_packed_group >> shift_amount  # Broadcasting scalar shift_amount\n",
    "            masked = (shifted & bitmask).cast(dtypes.float16)\n",
    "            masked = masked.reshape(N, -1)  # Flatten over packs_per_group\n",
    "\n",
    "            unpacked_values.append(masked)\n",
    "\n",
    "    #     # Stack the unpacked values and transpose to get correct order\n",
    "    #     # After stacking: Shape becomes (num_values_per_uint32, N, total_packed_values)\n",
    "        w_unpacked_stack = Tensor.stack(*unpacked_values, dim=0)\n",
    "        w_unpacked_group = w_unpacked_stack.permute(1, 2, 0).reshape(N, groups)  # Shape: (N, groups)\n",
    "\n",
    "    #     # Dequantize the unpacked weights\n",
    "        w_group = w_unpacked_group * scale_g + bias_g  # Shape: (N, groups)\n",
    "\n",
    "    #     # Extract the input activations for the current group\n",
    "        x_group = x_grouped[:, g, :]  # Shape: (M, groups)\n",
    "        \n",
    "        output = output.add(x_group.dot(w_group.transpose()))\n",
    "\n",
    "    #     # Perform matrix multiplication and accumulate the result\n",
    "        # print(x_group.shape, w_group.shape)\n",
    "        # partial_output = x_group @ w_group.transpose()  # Shape: (M, N)\n",
    "        # print(partial_output.realize())\n",
    "        # output += partial_output\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Tensor.randint((1024, 512), low=0, high=9, dtype=dtypes.uint32)\n",
    "s = Tensor.rand(1024, 64, dtype=dtypes.float16)\n",
    "b = Tensor.rand(1024, 64, dtype=dtypes.float16)\n",
    "x = Tensor.rand(1, 120, 4096, dtype=dtypes.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_matmul_tg(x, w, s, b).realize().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    o = Tensor.zeros(120, 1024)\n",
    "    for _ in range(64):\n",
    "        f = Tensor.rand(120, 64, dtype=dtypes.float16)\n",
    "        g = Tensor.rand(64, 1024, dtype=dtypes.float16)\n",
    "        o = o.add(f.dot(g))\n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func().realize().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timing(\"Time: \"):\n",
    "    f @ g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timing(\"Time: \"):\n",
    "    (w.T @ s).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haha():\n",
    "    return jp + jp\n",
    "\n",
    "with Timing(\"Time: \"):\n",
    "    haha().realize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qmm(x, w, scales, biases, width=4):\n",
    "    w_full = Tensor.cat(\n",
    "        *[(w // (2**i))[..., None] for i in range(0, 32, width)], dim=-1\n",
    "    )\n",
    "    w_full = w_full.reshape(len(w), scales.shape[-1], -1)\n",
    "    w_full = scales[..., None] * w_full + biases[..., None]\n",
    "    w_full = w_full.reshape(len(w), -1)\n",
    "\n",
    "    return x.dot(w_full.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_bits(w, bits, start):\n",
    "    shift_left = 32 - (start + bits)\n",
    "    shift_right = shift_left + start\n",
    "    return (w * (2**shift_left)) // (2**shift_right)\n",
    "\n",
    "\n",
    "def qmm(x, w, scales, biases, bits=4):\n",
    "    w_full = Tensor.cat(\n",
    "        *[select_bits(w, bits, i)[..., None] for i in range(0, 32, bits)], dim=-1\n",
    "    )\n",
    "    w_full = w_full.reshape(len(w), scales.shape[-1], -1)\n",
    "    w_full = scales[..., None] * w_full + biases[..., None]\n",
    "    return x.dot(w_full.reshape(len(w), -1).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Tensor.randint((1024, 512), low=0, high=9, dtype=dtypes.uint32)\n",
    "s = Tensor.rand(1024, 64, dtype=dtypes.float16)\n",
    "b = Tensor.rand(1024, 64, dtype=dtypes.float16)\n",
    "x = Tensor.rand(1, 120, 4096, dtype=dtypes.float16)\n",
    "\n",
    "# with Timing(\"time:\"):\n",
    "#     qmm(x, w, s, b).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timing(\"time:\"):\n",
    "    qmm(x, w, s, b).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = qmm(x, w, s, b).realize().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = mx.quantized_matmul(mx.array(x.numpy()), mx.array(w.numpy()), scales=mx.array(s.numpy()), biases=mx.array(b.numpy()), transpose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.shape, ln.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(lm == ln).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = Tensor([[1, 2], [2, 3]])\n",
    "jp = Tensor([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll[jp].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_bits(w, bits, start):\n",
    "    # Use integer floor division and modulo\n",
    "    return (w // (1 << start)) % (1 << bits)\n",
    "\n",
    "def qmm(x, w, scales, biases, bits=4):\n",
    "    total = None\n",
    "    num_segments = 32 // bits  # Number of segments based on bit width\n",
    "    \n",
    "    for i in range(num_segments):\n",
    "        start = i * bits\n",
    "        \n",
    "        # Extract quantized weights\n",
    "        w_i = select_bits(w, bits, start)\n",
    "        \n",
    "        # Reshape if necessary to match scales and biases dimensions\n",
    "        # Adjust the dimensions based on your data shapes\n",
    "        # You might need to reshape or expand dimensions appropriately\n",
    "        # Here it's assumed w_i has shape [input_dim, output_dim]\n",
    "        w_i = w_i.reshape(-1, scales.shape[-1])\n",
    "        \n",
    "        # Dequantize weights\n",
    "        scale = scales[..., i]\n",
    "        bias = biases[..., i]\n",
    "        w_dequant = w_i * scale + bias\n",
    "        \n",
    "        # Compute partial dot product and accumulate\n",
    "        res = x.dot(w_dequant)\n",
    "        if total is None:\n",
    "            total = res\n",
    "        else:\n",
    "            total += res\n",
    "    \n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = qmm(x, w, s, b).realize().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jp = (w // (1 << 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jp % (1 << 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = [Tensor([[1,2], [3,4]])[..., None], Tensor([[1,2], [3,4]])[..., None]]\n",
    "Tensor.cat(*ll, dim=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll[0][..., None].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinygrad import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = nn.Linear(4096, 4096)\n",
    "with Timing(\"time:\"):\n",
    "    linear(x).realize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLXQuantizedLinear:\n",
    "  def __init__(self, in_features, out_features, bits=4, group_size=64, bias=False):\n",
    "    assert in_features % group_size == 0\n",
    "    assert 32 % bits == 0\n",
    "    assert (in_features * bits) % 32 == 0\n",
    "    self.weight = Tensor.kaiming_uniform(out_features, (in_features * bits) // 32, dtype=dtypes.uint32)\n",
    "    self.scales = Tensor.kaiming_uniform(out_features, in_features // group_size, dtype=dtypes.half)\n",
    "    if bias:\n",
    "      self.biases = Tensor.kaiming_uniform(out_features, in_features // group_size, dtype=dtypes.half)\n",
    "    else:\n",
    "      self.biases = Tensor.zeros(out_features, in_features // group_size, dtype=dtypes.half)\n",
    "    self.bits = bits\n",
    "    self.group_size = group_size\n",
    "\n",
    "  def __call__(self, x):\n",
    "    w_full = Tensor.cat(\n",
    "        *[(self.weight // (2**i))[..., None] for i in range(0, 32, self.bits)], dim=-1\n",
    "    )\n",
    "    w_full = w_full.reshape(len(self.weight), self.scales.shape[-1], -1)\n",
    "    w_full = self.scales[..., None] * w_full + self.biases[..., None]\n",
    "    w_full = w_full.reshape(len(self.weight), -1)\n",
    "\n",
    "    return x.dot(w_full.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = MLXQuantizedLinear(4096, 4096)\n",
    "with Timing(\"time:\"):\n",
    "    linear(x).realize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = mx.array(np.random.randint((4096, 512), dtype=np.uint32))\n",
    "s = mx.array(np.random.rand(4096, 64).astype(np.half))\n",
    "b = mx.array(np.random.rand(4096, 64).astype(np.float16))\n",
    "x = mx.array(np.random.rand(1, 120, 4096).astype(np.float16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = mlx_nn.QuantizedLinear(4096, 4096)\n",
    "%timeit linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = mlx_nn.Linear(4096, 4096)\n",
    "%timeit linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = mlx_nn.Linear(4096, 4096)\n",
    "t = time.time()\n",
    "linear(x)\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = mlx_nn.QuantizedLinear(4096, 4096)\n",
    "t = time.time()\n",
    "linear(x)\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLXQuantizedEmbedding:\n",
    "  def __init__(self, vocab_size, embed_size, bits = 4, group_size= 64):\n",
    "    self.vocab_sz, self.embed_sz = vocab_size, embed_size\n",
    "    self.bits = bits\n",
    "    self.group_size = group_size\n",
    "    self.weight = Tensor.glorot_uniform(vocab_size, (embed_size * bits) // 32)\n",
    "    self.scales = Tensor.glorot_uniform(vocab_size, embed_size // group_size)\n",
    "    \n",
    "  def __call__(self, x):\n",
    "      s = x.shape\n",
    "      x = x.flatten()\n",
    "      w = self.weight[x]\n",
    "      scales = self.scales[x]\n",
    "      w_full = Tensor.cat(\n",
    "        *[(w // (2**i))[..., None] for i in range(0, 32, self.bits)], dim=-1\n",
    "      )\n",
    "      w_full = scales[..., None] * w_full.reshape(len(w), scales.shape[-1], -1)\n",
    "      return w_full.reshape(*s, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = nn.Embedding(128256, 4096)\n",
    "with Timing(\"Time it:\"):\n",
    "    emb(Tensor.arange(32)).realize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Tensor.randint((1024, 512), low=0, high=9, dtype=dtypes.uint32)\n",
    "s = Tensor.rand(1024, 64, dtype=dtypes.float16)\n",
    "b = Tensor.rand(1024, 64, dtype=dtypes.float16)\n",
    "x = Tensor.rand(1, 120, 4096, dtype=dtypes.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = mx.array(np.random.randint(low=0, high=9, size=(128256, 512)).astype(np.uint32))\n",
    "s = mx.array(np.random.rand(128256, 64).astype(np.half))\n",
    "b = mx.array(np.zeros((128256, 64)).astype(np.float16))\n",
    "x = mx.arange(32, dtype=mx.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = MLXQuantizedEmbedding(128256, 4096)\n",
    "with Timing(\"Time it:\"):\n",
    "    emb(Tensor.arange(32)).realize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = mlx_nn.QuantizedEmbedding(128256, 4096)\n",
    "emb.weight = w\n",
    "emb.scales = s\n",
    "emb.biases = b\n",
    "emb(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = MLXQuantizedEmbedding(128256, 4096)\n",
    "emb.weight = Tensor(np.array(w))\n",
    "emb.scales = Tensor(np.array(s))\n",
    "emb(Tensor.arange(32)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb.scales.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = MLXQuantizedEmbedding(128256, 4096)\n",
    "emb(Tensor.arange(32)).numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generate a random integer array of shape (x, y)\n",
    "result = np.random.randint(low=0, high=10, size=(3, 4))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLXQuantizedLinear:\n",
    "  def __init__(self, in_features, out_features, bits=4, group_size=64, bias=False):\n",
    "    self.weight = Tensor.randint((4096, 512), low=0, high=9, dtype=dtypes.uint32).realize()\n",
    "    self.scales = Tensor.rand(4096, 64, dtype=dtypes.half).realize()\n",
    "    self.biases = Tensor.rand(4096, 64, dtype=dtypes.half).realize()\n",
    "    self.bits = bits\n",
    "    self.group_size = group_size\n",
    "\n",
    "  def __call__(self, x):\n",
    "    w_full = Tensor.cat(\n",
    "        *[select_bits(self.weight, self.bits, i)[..., None] for i in range(0, 32, self.bits)], dim=-1\n",
    "    )\n",
    "    print(w_full.shape)\n",
    "    w_full = w_full.reshape(len(self.weight), self.scales.shape[-1], -1)\n",
    "    w_full = self.scales[..., None] * w_full + self.biases[..., None]\n",
    "    return x.linear(w_full.reshape(len(self.weight), -1).T)\n",
    "\n",
    "def select_bits(w, bits, start):\n",
    "    shift_left = 32 - (start + bits)\n",
    "    shift_right = shift_left + start\n",
    "    return (w * (2**shift_left)) // (2**shift_right)\n",
    "\n",
    "# class MLXQuantizedLinearNew:\n",
    "#   def __init__(self, in_features, out_features, bits=4, group_size=64, bias=False):\n",
    "#     self.weight = Tensor.randint((4096, 512), low=0, high=9, dtype=dtypes.uint32)\n",
    "#     self.scales = Tensor.rand(4096, 64, dtype=dtypes.half)\n",
    "#     self.biases = Tensor.rand(4096, 64, dtype=dtypes.half)\n",
    "#     self.bits = bits\n",
    "#     self.group_size = group_size\n",
    "    \n",
    "#   def old_call(self, x):\n",
    "#     w_full = Tensor.cat(\n",
    "#         *[select_bits(self.weight, self.bits, i)[..., None] for i in range(0, 32, self.bits)], dim=-1\n",
    "#     )\n",
    "#     print(w_full.shape)\n",
    "#     w_full = w_full.reshape(len(self.weight), self.scales.shape[-1], -1)\n",
    "#     w_full = self.scales[..., None] * w_full + self.biases[..., None]\n",
    "#     return x.linear(w_full.reshape(len(self.weight), -1).T)\n",
    "\n",
    "#   def __call__(self, x):\n",
    "#     res = []\n",
    "#     for i in range(0, 32, self.bits):\n",
    "#       w_full = select_bits(self.weight, self.bits, i).reshape(len(self.weight), self.scales.shape[-1], -1)\n",
    "#       w_full = self.scales[..., None] * w_full + self.biases[..., None]\n",
    "#       res.append(x.linear(w_full.reshape(len(self.weight), -1)).realize())\n",
    "#     # new = x.linear(Tensor.cat(*res, dim=-1).reshape(len(self.weight), -1).T)\n",
    "#     return res\n",
    "#     # old = self.old_call(x)\n",
    "#     # return new.realize(), old.realize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinygrad import TinyJit\n",
    "import time\n",
    "import os\n",
    "os.environ[\"METAL\"] = \"1\"\n",
    "# os.environ[\"CLANG\"] = \"1\"\n",
    "os.environ[\"METAL_XCODE\"] = \"1\"\n",
    "os.environ[\"DISABLE_COMPILER_CACHE\"] = \"1\"\n",
    "import numpy as np\n",
    "import mlx.core as mx\n",
    "from tinygrad import Tensor, dtypes, TinyJit\n",
    "from tinygrad.helpers import Timing, Context\n",
    "import mlx.core as mx\n",
    "from mlx import nn as mlx_nn\n",
    "from tinygrad import nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Tensor.rand(1, 1, 4096)\n",
    "mlx = MLXQuantizedLinearNew(4096, 4096)\n",
    "with Context(DEBUG=2):\n",
    "    ll = mlx(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll[0].realize().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll[1].realize().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Tensor.rand(1, 1, 4096)\n",
    "mlx = MLXQuantizedLinear(4096, 4096)\n",
    "with Context(DEBUG=4):\n",
    "    ll = mlx(x).realize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor.linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLXQuantizedLinear:\n",
    "    def __init__(self, in_features, out_features, bits=4, group_size=64, bias=False):\n",
    "        self.weight = Tensor.randint((4096, 512), low=0, high=2**32, dtype=dtypes.uint32)\n",
    "        self.scales = Tensor.rand(4096, 64, dtype=dtypes.half)\n",
    "        self.biases = Tensor.rand(4096, 64, dtype=dtypes.half)\n",
    "        self.bits = bits\n",
    "        self.group_size = group_size\n",
    "\n",
    "    def __call__(self, x):\n",
    "        bits = self.bits\n",
    "        num_positions = 32 // bits  # e.g., 8 for 4-bit quantization\n",
    "        \n",
    "        # Create tensor of start positions for bit extraction\n",
    "        starts = Tensor.arange(np.arange(0, 32, bits), dtype=dtypes.uint32)  # Shape: (bits_per_value,)\n",
    "        \n",
    "        # Expand dimensions of weight tensor for broadcasting\n",
    "        w_expanded = self.weight[..., None]  # Shape: (4096, 512, 1)\n",
    "        \n",
    "        # Perform vectorized bit extraction\n",
    "        w_bits = (w_expanded >> starts) & ((1 << bits) - 1)  # Shape: (4096, 512, bits_per_value)\n",
    "        \n",
    "        # Reshape w_bits to combine the last two dimensions\n",
    "        # w_bits = w_bits.reshape(len(self.weight), -1)  # Shape: (4096, 4096)\n",
    "        \n",
    "        # Reshape w_bits to match the scales and biases dimensions\n",
    "        w_full = w_bits.reshape(len(self.weight), self.scales.shape[-1], -1)  # Shape: (4096, 64, 64)\n",
    "        \n",
    "        # Apply scales and biases\n",
    "        w_full = self.scales[..., None] * w_full + self.biases[..., None]\n",
    "        \n",
    "        # Final reshape for the linear operation\n",
    "        w_full = w_full.reshape(len(self.weight), -1).T  # Shape: (4096, 4096)\n",
    "        \n",
    "        # Perform the linear operation\n",
    "        return x.linear(w_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starts = Tensor.arange(0, 32, 4, dtype=dtypes.uint32)\n",
    "x = Tensor.ones(30,30, dtype=dtypes.uint32)\n",
    "x >> starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Tensor.rand(1, 1, 4096)\n",
    "tiny = nn.Linear(4096, 4096, bias=False)\n",
    "with Context(DEBUG=4):\n",
    "    ll = tiny(y).realize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlx = MLXQuantizedLinear(4096, 4096)\n",
    "tiny = nn.Linear(4096, 4096)\n",
    "for i in [1]*10:\n",
    "    x = Tensor.rand(1, i, 4096)\n",
    "    st = time.time()\n",
    "    tiny(x).realize()\n",
    "    st1 = time.time()\n",
    "    mlx(x).realize()\n",
    "    st2 = time.time()\n",
    "    print(\"-\"*20)\n",
    "    print(f\"{i}\\nmlx: {st2-st1}\\n tiny: {st1-st}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlx_nn.QuantizedLinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = Tensor.cat(*[Tensor.arange(512)[..., None]]*8, dim=-1).realize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = ll.reshape(64,64).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm * lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "504 * 504"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = Tensor.arange(6400).reshape(100,64,1)\n",
    "l2 = Tensor.ones(100,64,64)\n",
    "kp = (l1 * l2).realize().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import MllamaForConditionalGeneration, AutoProcessor\n",
    "\n",
    "model_id = \"unsloth/Llama-3.2-11B-Vision-Instruct\"\n",
    "# model = MllamaForConditionalGeneration.from_pretrained(model_id, device_map=\"auto\", torch_dtype=torch.bfloat16)\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "messages = [\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": [\n",
    "                {\"type\": \"image\"},\n",
    "                {\"type\": \"text\", \"text\": \"What does the image show?\"}\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "]\n",
    "text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "\n",
    "url = \"https://llava-vl.github.io/static/images/view.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "print(text, image)\n",
    "\n",
    "# inputs = processor(text=text, images=image, return_tensors=\"np\")\n",
    "inputs = processor(text, image, return_tensors=\"np\")\n",
    "# output = model.generate(**inputs, max_new_tokens=25)\n",
    "# print(processor.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"hi explain life?\"}\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "]\n",
    "text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "\n",
    "# url = \"https://llava-vl.github.io/static/images/view.jpg\"\n",
    "# image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "inputs = processor(text=text, images=None, return_tensors=\"pt\").to(model.device)\n",
    "output = model.language_model.generate(**inputs, max_new_tokens=25)\n",
    "print(processor.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.language_model.save_pretrained(\"/Users/varb/mllama_language/\", save_peft_format=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.language_model.model.embed_tokens.num_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinygrad.tensor import Tensor\n",
    "\n",
    "def select_bits(w, bits):\n",
    "    num_bits = 32\n",
    "    # Create a tensor for shifts as an unsigned integer\n",
    "    shifts = Tensor.arange(num_bits - bits, -1, -bits)  # Ensure shifts are in appropriate range\n",
    "\n",
    "    # Expand dimensions of w for broadcasting\n",
    "    expanded_w = w[..., None]  # Add a new dimension for broadcasting\n",
    "\n",
    "    # Perform bitwise operations in a vectorized manner\n",
    "    selected_bits = (expanded_w.rshift(shifts)) & ((1 << bits) - 1)\n",
    "    \n",
    "    return selected_bits\n",
    "\n",
    "# Example usage\n",
    "weight = Tensor(np.random.randint(0, 2**32, (32,), dtype=np.uint32))  # Example weight tensor as uint32\n",
    "bits = 8\n",
    "\n",
    "# Apply the function\n",
    "w_full = select_bits(weight.astype('uint32'), bits)\n",
    "\n",
    "# Output the shape and selected bits\n",
    "print(w_full.shape)\n",
    "print(w_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinygrad.tensor import Tensor\n",
    "\n",
    "def select_bits(w, bits):\n",
    "    num_bits = 32\n",
    "    # Create a tensor for shifts as an unsigned integer\n",
    "    shifts = Tensor.arange(num_bits - bits, -1, -bits, dtype='uint32')  # Ensure shifts are uint32\n",
    "\n",
    "    # Expand dimensions of w for broadcasting\n",
    "    expanded_w = w[..., None]  # Add a new dimension for broadcasting\n",
    "\n",
    "    # Perform bitwise operations in a vectorized manner\n",
    "    selected_bits = (expanded_w >> shifts) & ((1 << bits) - 1)\n",
    "    \n",
    "    return selected_bits\n",
    "\n",
    "# Example usage\n",
    "weight = Tensor(np.random.randint(0, 2**32, (32,), dtype=np.uint32))  # Example weight tensor as uint32\n",
    "bits = 8\n",
    "\n",
    "# Apply the function\n",
    "w_full = select_bits(weight, bits)\n",
    "\n",
    "# Output the shape and selected bits\n",
    "print(w_full.shape)\n",
    "print(w_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "512 / 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifts = mx.array([2**i for i in range(0, 32, 4)], dtype=mx.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifts[None:None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = mx.ones((100,100), dtype=mx.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll.sum(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_ll.contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.tanh(m_ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(10000)[ll.flatten() == int(1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.functional.pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_attention_mask = torch.ones((100, 100), dtype=torch.float32)\n",
    "# inverted_cross_attn_mask = 0.0 - cross_attention_mask\n",
    "# cross_attention_mask = inverted_cross_attn_mask.masked_fill(\n",
    "#     inverted_cross_attn_mask.to(torch.bool), torch.finfo(torch.float32).min\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_attention_mask[cross_attention_mask==1.0] = -1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_attention_mask = np.ones((100, 100), dtype=np.float32)\n",
    "cross_attention_mask[cross_attention_mask==1.0] = -1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = cross_attention_mask == 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_attention_mask[ll] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlx.core as mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = torch.randint(0, 10, (10, 10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = ll.repeat_interleave(4, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_ll = mx.array(ll.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_lm = mx.repeat(m_ll, 4, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.tile(m_ll, (1, 1, 10, 1)).shape, m_ll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.expand_dims(m_ll, axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_ll.transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(lm.numpy() == m_lm).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ll.repeat(1,1,4,1).numpy() == mx.tile(m_ll, (1,1,4,1))).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll.repeat(1,1,4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.tile(m_ll, (1,1,4,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 ()\n"
     ]
    }
   ],
   "source": [
    "def check(l, m, *_, **__):\n",
    "    print(l, m, _)\n",
    "    # pass\n",
    "    \n",
    "l = 1\n",
    "m = 2\n",
    "check(l, m=1)e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e90784ba642c4e28abed772a65c171e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/4.36k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1cfa7b77ea3444fa38e4c57df5cdc01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/4.61M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b5999055a774741ac55eb8fb474c6a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tok = AutoTokenizer.from_pretrained(\"mlx-community/DeepSeek-Coder-V2-Lite-Instruct-4bit-mlx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "where(): incompatible function arguments. The following argument types are supported:\n    1. where(condition: Union[scalar, array], x: Union[scalar, array], y: Union[scalar, array], /, *, stream: Union[None, Stream, Device] = None) -> array\n\nInvoked with types: mlx.core.array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m flat_mask \u001b[38;5;241m=\u001b[39m mx\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m0\u001b[39m])  \u001b[38;5;66;03m# Replace with your actual data\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Use mlx.core.where to get indices of non-zero elements\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[43mmx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(indices)\n",
      "\u001b[0;31mTypeError\u001b[0m: where(): incompatible function arguments. The following argument types are supported:\n    1. where(condition: Union[scalar, array], x: Union[scalar, array], y: Union[scalar, array], /, *, stream: Union[None, Stream, Device] = None) -> array\n\nInvoked with types: mlx.core.array"
     ]
    }
   ],
   "source": [
    "import mlx.core as mx\n",
    "\n",
    "# Example input array\n",
    "flat_mask = mx.array([0, 1, 0, 2, 3, 0])  # Replace with your actual data\n",
    "\n",
    "# Use mlx.core.where to get indices of non-zero elements\n",
    "indices = mx.where(flat_mask != 0)\n",
    "\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "boolean indices are not yet supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m ll \u001b[38;5;241m=\u001b[39m mx\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m \u001b[43mll\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: boolean indices are not yet supported"
     ]
    }
   ],
   "source": [
    "ll = mx.array([1, 2, 3])\n",
    "ll[[True, False, True]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([True, False, False], dtype=bool)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx.where(ll > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = mx.zeros((4, 40, 40 ,1280))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with remapped shapes [original->remapped]: (2,2)  and requested shape (4,2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/exo-venv/lib/python3.12/site-packages/numpy/lib/_arraypad_impl.py:760\u001b[0m, in \u001b[0;36mpad\u001b[0;34m(array, pad_width, mode, **kwargs)\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`pad_width` must be of integral type.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    759\u001b[0m \u001b[38;5;66;03m# Broadcast to shape (array.ndim, 2)\u001b[39;00m\n\u001b[0;32m--> 760\u001b[0m pad_width \u001b[38;5;241m=\u001b[39m \u001b[43m_as_pairs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpad_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(mode):\n\u001b[1;32m    763\u001b[0m     \u001b[38;5;66;03m# Old behavior: Use user-supplied function with np.apply_along_axis\u001b[39;00m\n\u001b[1;32m    764\u001b[0m     function \u001b[38;5;241m=\u001b[39m mode\n",
      "File \u001b[0;32m~/miniconda3/envs/exo-venv/lib/python3.12/site-packages/numpy/lib/_arraypad_impl.py:534\u001b[0m, in \u001b[0;36m_as_pairs\u001b[0;34m(x, ndim, as_index)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt contain negative values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    532\u001b[0m \u001b[38;5;66;03m# Converting the array with `tolist` seems to improve performance\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;66;03m# when iterating and indexing the result (see usage in `pad`)\u001b[39;00m\n\u001b[0;32m--> 534\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/miniconda3/envs/exo-venv/lib/python3.12/site-packages/numpy/lib/_stride_tricks_impl.py:422\u001b[0m, in \u001b[0;36mbroadcast_to\u001b[0;34m(array, shape, subok)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_broadcast_to_dispatcher, module\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbroadcast_to\u001b[39m(array, shape, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    378\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Broadcast an array to a new shape.\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;124;03m           [1, 2, 3]])\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 422\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_broadcast_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreadonly\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/exo-venv/lib/python3.12/site-packages/numpy/lib/_stride_tricks_impl.py:358\u001b[0m, in \u001b[0;36m_broadcast_to\u001b[0;34m(array, shape, subok, readonly)\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall elements of broadcast shape must be non-\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    356\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    357\u001b[0m extras \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 358\u001b[0m it \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnditer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmulti_index\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrefs_ok\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mzerosize_ok\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mextras\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_flags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreadonly\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitershape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m it:\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;66;03m# never really has writebackifcopy semantics\u001b[39;00m\n\u001b[1;32m    363\u001b[0m     broadcast \u001b[38;5;241m=\u001b[39m it\u001b[38;5;241m.\u001b[39mitviews[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with remapped shapes [original->remapped]: (2,2)  and requested shape (4,2)"
     ]
    }
   ],
   "source": [
    "np.pad(ll, [(0,0), (0,0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "ll = torch.zeros((4, 40, 40 ,1280))\n",
    "ans = torch.functional.F.pad(ll, (0, 0, 0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = mx.zeros((4, 40, 40 ,1280))\n",
    "ans_mx = mx.pad(ll, [(0,0), (0,0), (0,10), (0,0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 40, 50, 1280)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans.numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 40, 50, 1280)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_mx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1m/qn3qfmjs79n0htlpmzqmyjsh0000gp/T/ipykernel_15772/3403021104.py:1: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  np.equal(ans, ans_mx).all()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1, dtype=torch.uint8)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.equal(ans, ans_mx).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 40, 50, 1280)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_mx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 40, 50, 1280])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[matmul] Last dimension of first input with shape (4,40,40,1280) must match second to last dimension of second input with shape (1280,40,40,4).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mll\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mll\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: [matmul] Last dimension of first input with shape (4,40,40,1280) must match second to last dimension of second input with shape (1280,40,40,4)."
     ]
    }
   ],
   "source": [
    "ll @ ll.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "npam = np.random.randint(low=0, high=2, size=(1, 6432, 1))\n",
    "am = mx.array(npam).astype(mx.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = am @ am.transpose(0, 2, 1) * -3.3895313892515355e+38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = torch.tensor(npam, dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttans = tt @ tt.transpose(-1, -2) * torch.finfo(torch.bfloat16).min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0, -0, -0, ..., -0, -0, -0],\n",
       "        [-0, -3.38953e+38, -0, ..., -0, -0, -3.38953e+38],\n",
       "        [-0, -0, -0, ..., -0, -0, -0],\n",
       "        ...,\n",
       "        [-0, -0, -0, ..., -0, -0, -0],\n",
       "        [-0, -0, -0, ..., -0, -0, -0],\n",
       "        [-0, -3.38953e+38, -0, ..., -0, -0, -3.38953e+38]]], dtype=bfloat16)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Got unsupported ScalarType BFloat16",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mttans\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Got unsupported ScalarType BFloat16"
     ]
    }
   ],
   "source": [
    "ttans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.3895313892515355e+38"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-3.3895313892515355e+38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.104e-05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.finfo(np.float16).tiny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exo-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
